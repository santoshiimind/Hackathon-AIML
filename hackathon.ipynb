{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23469,"status":"ok","timestamp":1727019396535,"user":{"displayName":"Santosh Kumar","userId":"07238666393258926867"},"user_tz":-330},"id":"k8939ySthHYu","outputId":"8dd0d114-7dfd-4ded-af5c-cc48512e550f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.preprocessing import StandardScaler, LabelEncoder\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","import xgboost as xgb\n","\n","# Load the datasets\n","train_data = pd.read_csv('/content/drive/My Drive/Hackathon/Train_set.csv')\n","test_data = pd.read_csv('/content/drive/My Drive/Hackathon/Test_set.csv', names=[\n","    \"ID\", \"loan_amnt\", \"loan_term\", \"interest_rate\", \"loan_grade\", \"loan_subgrade\",\n","    \"job_experience\", \"home_ownership\", \"annual_income\", \"income_verification_status\",\n","    \"loan_purpose\", \"state_code\", \"debt_to_income\", \"delinq_2yrs\", \"public_records\",\n","    \"revolving_balance\", \"total_acc\", \"interest_receive\", \"application_type\",\n","    \"last_week_pay\", \"total_current_balance\", \"total_revolving_limit\"\n","], low_memory=False)\n","\n","# Ensure numeric columns are converted properly\n","numeric_columns = ['loan_amnt', 'interest_rate', 'annual_income', 'debt_to_income',\n","                   'delinq_2yrs', 'public_records', 'revolving_balance', 'total_acc',\n","                   'interest_receive', 'last_week_pay', 'total_current_balance',\n","                   'total_revolving_limit']\n","\n","# Convert numeric columns (coercing invalid values to NaN)\n","for col in numeric_columns:\n","    train_data[col] = pd.to_numeric(train_data[col], errors='coerce')\n","    test_data[col] = pd.to_numeric(test_data[col], errors='coerce')\n","\n","# Separate features and target in train_data\n","X = train_data.drop(['default', 'ID'], axis=1)\n","y = train_data['default']\n","\n","# Store the original ID column from the test data\n","test_ids = test_data['ID']\n","\n","# Drop the ID column from test_data\n","test_data = test_data.drop('ID', axis=1)\n","\n","# Identify categorical columns and numerical columns\n","categorical_columns = ['loan_term', 'loan_grade', 'loan_subgrade', 'job_experience',\n","                       'home_ownership', 'income_verification_status', 'loan_purpose',\n","                       'state_code', 'application_type']\n","\n","# Label encode 'loan_grade' and 'loan_subgrade'\n","label_encoders = {}\n","for col in ['loan_grade', 'loan_subgrade']:\n","    le = LabelEncoder()\n","    all_values = pd.concat([X[col], test_data[col]]).unique()\n","    le.fit(all_values)\n","\n","    X[col] = le.transform(X[col])\n","    test_data[col] = le.transform(test_data[col])\n","    label_encoders[col] = le\n","\n","# OneHotEncode other categorical columns\n","X = pd.get_dummies(X, columns=[col for col in categorical_columns if col not in ['loan_grade', 'loan_subgrade']])\n","test_data = pd.get_dummies(test_data, columns=[col for col in categorical_columns if col not in ['loan_grade', 'loan_subgrade']])\n","\n","# Align train and test datasets to ensure the same number of columns\n","X, test_data = X.align(test_data, join='left', axis=1, fill_value=0)\n","\n","# Fix column names to remove special characters\n","X.columns = X.columns.str.replace(r'[\\[\\]<]', '', regex=True)\n","test_data.columns = test_data.columns.str.replace(r'[\\[\\]<]', '', regex=True)\n","\n","# Train-test split\n","X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Scale numeric features\n","scaler = StandardScaler()\n","X_train[numeric_columns] = scaler.fit_transform(X_train[numeric_columns])\n","X_val[numeric_columns] = scaler.transform(X_val[numeric_columns])\n","test_data[numeric_columns] = scaler.transform(test_data[numeric_columns])\n","\n","# Define XGBoost model and hyperparameter grid\n","xgb_model = xgb.XGBClassifier(objective='binary:logistic', eval_metric='logloss', use_label_encoder=False)\n","\n","param_grid = {\n","    'n_estimators': [100, 200],\n","    'learning_rate': [0.01, 0.1],\n","    'max_depth': [3, 5, 7],\n","    'subsample': [0.8, 1.0],\n","    'colsample_bytree': [0.8, 1.0]\n","}\n","\n","# GridSearchCV for XGBoost\n","grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)\n","grid_search.fit(X_train, y_train)\n","\n","# Get the best model\n","best_xgb_model = grid_search.best_estimator_\n","\n","# Predictions and evaluation\n","y_val_pred = best_xgb_model.predict(X_val)\n","\n","print(f\"Validation Accuracy: {accuracy_score(y_val, y_val_pred)}\")\n","print(\"Classification Report:\")\n","print(classification_report(y_val, y_val_pred))\n","print(\"Confusion Matrix:\")\n","print(confusion_matrix(y_val, y_val_pred))\n","\n","# Predict on test data\n","test_predictions = best_xgb_model.predict(test_data)\n","\n","# Prepare the submission file with the correct ID column\n","submission = pd.DataFrame({\n","    'ID': test_ids,  # Use the original test IDs\n","    'default': test_predictions\n","})\n","\n","# Save submission file\n","submission.to_csv('submission.csv', index=False)\n","\n","print(\"Submission file created successfully.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eL1EvneL8e6T","executionInfo":{"status":"ok","timestamp":1726999165306,"user_tz":-330,"elapsed":369222,"user":{"displayName":"Santosh Kumar","userId":"07238666393258926867"}},"outputId":"b83597dd-7dc8-4469-f439-13096eff958a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Fitting 3 folds for each of 48 candidates, totalling 144 fits\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [09:59:18] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["Validation Accuracy: 0.8738932116984169\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.88      0.96      0.92     14083\n","           1       0.83      0.61      0.70      4552\n","\n","    accuracy                           0.87     18635\n","   macro avg       0.86      0.78      0.81     18635\n","weighted avg       0.87      0.87      0.87     18635\n","\n","Confusion Matrix:\n","[[13516   567]\n"," [ 1783  2769]]\n","Submission file created successfully.\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.preprocessing import StandardScaler, LabelEncoder\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","import xgboost as xgb\n","\n","# Load the datasets\n","train_data = pd.read_csv('/content/drive/My Drive/Hackathon/Train_set.csv')\n","test_data = pd.read_csv('/content/drive/My Drive/Hackathon/Test_set.csv', names=[\n","    \"ID\", \"loan_amnt\", \"loan_term\", \"interest_rate\", \"loan_grade\", \"loan_subgrade\",\n","    \"job_experience\", \"home_ownership\", \"annual_income\", \"income_verification_status\",\n","    \"loan_purpose\", \"state_code\", \"debt_to_income\", \"delinq_2yrs\", \"public_records\",\n","    \"revolving_balance\", \"total_acc\", \"interest_receive\", \"application_type\",\n","    \"last_week_pay\", \"total_current_balance\", \"total_revolving_limit\"\n","], low_memory=False)\n","\n","# Ensure numeric columns are converted properly\n","numeric_columns = ['loan_amnt', 'interest_rate', 'annual_income', 'debt_to_income',\n","                   'delinq_2yrs', 'public_records', 'revolving_balance', 'total_acc',\n","                   'interest_receive', 'last_week_pay', 'total_current_balance',\n","                   'total_revolving_limit']\n","\n","# Convert numeric columns (coercing invalid values to NaN)\n","for col in numeric_columns:\n","    train_data[col] = pd.to_numeric(train_data[col], errors='coerce')\n","    test_data[col] = pd.to_numeric(test_data[col], errors='coerce')\n","\n","# Feature Engineering: Adding a few interaction features\n","train_data['loan_income_ratio'] = train_data['loan_amnt'] / train_data['annual_income']\n","test_data['loan_income_ratio'] = test_data['loan_amnt'] / test_data['annual_income']\n","\n","# Separate features and target in train_data\n","X = train_data.drop(['default', 'ID'], axis=1)\n","y = train_data['default']\n","\n","# Store the original ID column from the test data\n","test_ids = test_data['ID']\n","\n","# Drop the ID column from test_data\n","test_data = test_data.drop('ID', axis=1)\n","\n","# Identify categorical columns\n","categorical_columns = ['loan_term', 'loan_grade', 'loan_subgrade', 'job_experience',\n","                       'home_ownership', 'income_verification_status', 'loan_purpose',\n","                       'state_code', 'application_type']\n","\n","# Label encode 'loan_grade' and 'loan_subgrade'\n","label_encoders = {}\n","for col in ['loan_grade', 'loan_subgrade']:\n","    le = LabelEncoder()\n","    all_values = pd.concat([X[col], test_data[col]]).unique()\n","    le.fit(all_values)\n","\n","    X[col] = le.transform(X[col])\n","    test_data[col] = le.transform(test_data[col])\n","    label_encoders[col] = le\n","\n","# OneHotEncode other categorical columns\n","X = pd.get_dummies(X, columns=[col for col in categorical_columns if col not in ['loan_grade', 'loan_subgrade']])\n","test_data = pd.get_dummies(test_data, columns=[col for col in categorical_columns if col not in ['loan_grade', 'loan_subgrade']])\n","\n","# Align train and test datasets to ensure the same number of columns\n","X, test_data = X.align(test_data, join='left', axis=1, fill_value=0)\n","\n","# Fix column names to remove special characters\n","X.columns = X.columns.str.replace(r'[\\[\\]<]', '', regex=True)\n","test_data.columns = test_data.columns.str.replace(r'[\\[\\]<]', '', regex=True)\n","\n","# Train-test split\n","X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Scale numeric features\n","scaler = StandardScaler()\n","X_train[numeric_columns] = scaler.fit_transform(X_train[numeric_columns])\n","X_val[numeric_columns] = scaler.transform(X_val[numeric_columns])\n","test_data[numeric_columns] = scaler.transform(test_data[numeric_columns])\n","\n","# Define XGBoost model and extended hyperparameter grid\n","xgb_model = xgb.XGBClassifier(objective='binary:logistic', eval_metric='logloss', use_label_encoder=False)\n","\n","param_grid = {\n","    'n_estimators': [100, 200, 500],\n","    'learning_rate': [0.01, 0.05, 0.1],\n","    'max_depth': [3, 5, 7, 9],\n","    'subsample': [0.6, 0.8, 1.0],\n","    'colsample_bytree': [0.6, 0.8, 1.0],\n","    'gamma': [0, 0.1, 0.2],\n","    'min_child_weight': [1, 3, 5],\n","    'reg_alpha': [0, 0.01, 0.1],  # L1 regularization\n","    'reg_lambda': [1, 1.5, 2],  # L2 regularization\n","    'scale_pos_weight': [1, 2, 3]  # Adjust for class imbalance\n","}\n","\n","# GridSearchCV for XGBoost with 5-fold CV\n","grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\n","grid_search.fit(X_train, y_train)\n","\n","# Get the best model and train with early stopping\n","best_xgb_model = grid_search.best_estimator_\n","best_xgb_model.fit(X_train, y_train, eval_set=[(X_val, y_val)], early_stopping_rounds=10, verbose=True)\n","\n","# Predictions and evaluation\n","y_val_pred = best_xgb_model.predict(X_val)\n","\n","print(f\"Validation Accuracy: {accuracy_score(y_val, y_val_pred)}\")\n","print(\"Classification Report:\")\n","print(classification_report(y_val, y_val_pred))\n","print(\"Confusion Matrix:\")\n","print(confusion_matrix(y_val, y_val_pred))\n","\n","# Predict on test data\n","test_predictions = best_xgb_model.predict(test_data)\n","\n","# Prepare the submission file with the correct ID column\n","submission = pd.DataFrame({\n","    'ID': test_ids,  # Use the original test IDs\n","    'default': test_predictions\n","})\n","\n","# Save submission file\n","submission.to_csv('submission.csv', index=False)\n","\n","print(\"Submission file created successfully.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VlV0z2E7LOOI","outputId":"cb771fea-1261-41ca-f9b4-8182d276f77d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Fitting 5 folds for each of 78732 candidates, totalling 393660 fits\n"]}]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}